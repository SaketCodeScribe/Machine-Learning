{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  size  price classlabel\n",
      "0  green     1   10.1     class1\n",
      "1    red     2   13.5     class2\n",
      "2   blue     3   15.3     class1\n",
      "{'class1': 0, 'class2': 1}\n",
      "   color  size  price  classlabel\n",
      "0  green     1   10.1           0\n",
      "1    red     2   13.5           1\n",
      "2   blue     3   15.3           0\n",
      "[[1 1 10.1]\n",
      " [2 2 13.5]\n",
      " [0 3 15.3]]\n",
      "[[ 0.   1.   0.   1.  10.1]\n",
      " [ 0.   0.   1.   2.  13.5]\n",
      " [ 1.   0.   0.   3.  15.3]]\n",
      "  (0, 1)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t10.1\n",
      "  (1, 3)\t2.0\n",
      "  (1, 4)\t13.5\n",
      "  (2, 3)\t3.0\n",
      "  (2, 4)\t15.3\n",
      "   size  price  color_blue  color_green  color_red\n",
      "0     1   10.1           0            1          0\n",
      "1     2   13.5           0            0          1\n",
      "2     3   15.3           1            0          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "['green', 'M', 10.1, 'class1'],\n",
    "['red', 'L', 13.5, 'class2'],\n",
    "['blue', 'XL', 15.3, 'class1']])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "size_mapping = {\n",
    "        'XL':3,\n",
    "        'L':2,\n",
    "        'M':1}\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "print(df)\n",
    "#inv_size_mapping = {v:k for k,v in size_mapping.items()}\n",
    "#df['size'] = df['size'].map(inv_size_mapping)\n",
    "#print(df)\n",
    "import numpy as np\n",
    "class_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))}\n",
    "print(class_mapping)\n",
    "df['classlabel'] = df['classlabel'].map(class_mapping)\n",
    "print(df)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df[['color', 'size', 'price']].values\n",
    "X = df[['color', 'size', 'price']].values\n",
    "color_le = LabelEncoder()\n",
    "X[:,0] = color_le.fit_transform(X[:,0])\n",
    "print(X)\n",
    "ohe = OneHotEncoder(categorical_features=[0])\n",
    "ohe.fit_transform(X).toarray()\n",
    "print(ohe.fit_transform(X).toarray())\n",
    "print(ohe.fit_transform(X))\n",
    "df1 = pd.get_dummies(df[['color', 'size', 'price']])\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol','Malic acid', 'Ash',\n",
    "'Alcalinity of ash', 'Magnesium','Total phenols', 'Flavanoids','Nonflavanoid phenols','Proanthocyanins',\n",
    "'Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']\n",
    "print('Class labels:', np.unique(df_wine['Class label']))\n",
    "df_wine.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "print(type(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression(penalty='l1')\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "lr.coef_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue', 'green', 'red', 'cyan','magenta', 'yellow', 'black',\n",
    "          'pink', 'lightgreen', 'lightblue','gray', 'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "for c in np.arange(0, 6):\n",
    "    lr = LogisticRegression(penalty='l1', C=10**c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**(c))\n",
    "weights = np.array(weights)\n",
    "print(weights.shape)\n",
    "print(params)\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column], label=df_wine.columns[column+1],color=color)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-3), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',\n",
    "bbox_to_anchor=(1.38, 1.03), ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "for p in combinations([1,2,3,4], r=3):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "z=np.append(X_train[:,y==1],X_train[:,y==4],axis=1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.columns[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = df_wine.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=10000,random_state=0,n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
    "                            feat_labels[f],\n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(X_train.shape[1]),importances[indices],color='lightblue',align='center')\n",
    "plt.xticks(range(X_train.shape[1]),feat_labels, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol','Malic acid', 'Ash',\n",
    "'Alcalinity of ash', 'Magnesium','Total phenols', 'Flavanoids','Nonflavanoid phenols','Proanthocyanins',\n",
    "'Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features,\n",
    "                 scoring=accuracy_score,test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train,X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            for p in combinations(self.indices_, r=dim-1):\n",
    "                score = self._calc_score(X_train, y_train,X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "    def _calc_score(self, X_train, y_train,X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "sbs.fit(X_train, y_train)\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol','Malic acid', 'Ash',\n",
    "'Alcalinity of ash', 'Magnesium','Total phenols', 'Flavanoids','Nonflavanoid phenols','Proanthocyanins',\n",
    "'Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "print(type(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "estimet = clone(knn)\n",
    "estimet.fit(X_t[:,1:3])\n",
    "estimet.predict(X_test[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, 0.25)\n",
    "y = np.arange(-5, 5, 0.25)\n",
    "xx, yy = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(x.ravel(),y.ravel()):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol','Malic acid', 'Ash',\n",
    "'Alcalinity of ash', 'Magnesium','Total phenols', 'Flavanoids','Nonflavanoid phenols','Proanthocyanins',\n",
    "'Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "est = clone(knn)\n",
    "select_subset=[]\n",
    "scores=[]\n",
    "k = range(1,X_train_std.shape[1]+1)\n",
    "for i in k:\n",
    "    score=[]\n",
    "    subset=[]\n",
    "    for p in combinations(range(X_train.shape[1]), r=i):\n",
    "        est.fit(X_train[:,p],y_train)\n",
    "        score.append(est.score(X_train[:,p],y_train))\n",
    "        subset.append(p)\n",
    "    best = np.argmax(score)\n",
    "    select_subset.append(subset[best])\n",
    "    scores.append(score[best])\n",
    "print(scores)\n",
    "plt.plot(k, scores, marker='o')\n",
    "plt.ylim([0.7, 1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(knn.score(X_train_std,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
